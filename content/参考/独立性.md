在概率论和统计学中，两个随机变量（或事件）相互独立意味着它们的出现不受彼此的影响，或者说它们之间没有相互依赖关系。具体来说，如果两个随机变量 X 和 Y 相互独立，那么以下条件成立：

1. 事件 X 的发生与事件 Y 的发生是独立的，意味着知道一个事件发生与否不会提供关于另一个事件发生与否的信息。

2. 随机变量 X 的概率分布不受随机变量 Y 的值的影响，反之亦然。换句话说，它们之间的[联合概率分布](联合概率分布.md)可以拆分为各自的[边缘概率分布](边缘概率分布.md)。

独立性是概率论和统计学中一个重要的概念，它在许多问题的建模和分析中起着关键作用。例如，在概率分布之间的独立性假设下，可以简化复杂的计算和推断。当我们处理多个随机事件或随机变量时，了解它们是否相互独立对于正确建模和预测结果至关重要。